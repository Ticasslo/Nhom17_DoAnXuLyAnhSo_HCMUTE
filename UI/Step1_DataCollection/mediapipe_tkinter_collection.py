import os
import re
import time
import cv2
import warnings
import threading
from queue import Queue, Empty, Full
import numpy as np
from PIL import Image, ImageTk
import tkinter as tk
from tkinter import filedialog, scrolledtext
import sys

import mediapipe as mp
from mediapipe.tasks.python import vision

# Giáº£m warning log
warnings.filterwarnings("ignore", category=UserWarning)

# 1. CONFIGURATION
SOURCE = 0  # 0 = webcam máº·c Ä‘á»‹nh

# Performance settings
NUM_HANDS = 1  # 2 ngÆ°á»i (má»—i ngÆ°á»i 2 tay) - cÃ³ thá»ƒ giáº£m xuá»‘ng 2 náº¿u chá»‰ cáº§n 1 ngÆ°á»i
MIN_DETECTION_CONFIDENCE = 0.6  # NgÆ°á»¡ng cho palm detector (BlazePalm)
MIN_PRESENCE_CONFIDENCE = 0.5   # NgÆ°á»¡ng Ä‘á»ƒ trigger re-detection (tháº¥p hÆ¡n = re-detect thÆ°á»ng xuyÃªn hÆ¡n)
MIN_TRACKING_CONFIDENCE = 0.5   # NgÆ°á»¡ng cho hand tracking (landmark model)

# Filtering thresholds
HAND_MIN_AREA_RATIO = 0.0025   # ~0.25% diá»‡n tÃ­ch frame (bá» box quÃ¡ nhá»)
HAND_MAX_AREA_RATIO = 0.35     # ~35% diá»‡n tÃ­ch frame (bá» box quÃ¡ lá»›n)
HANDEDNESS_SCORE_THRESHOLD = 0.6  # NgÆ°á»¡ng confidence tá»‘i thiá»ƒu cho handedness

# Display settings
PRINT_EVERY_N_FRAMES = 200
WINDOW_WIDTH = 1080
WINDOW_HEIGHT = 660

# EMA Smoothing settings
ENABLE_EMA_SMOOTHING = True  # Enable Exponential Moving Average smoothing
EMA_ALPHA = 0.5  # Smoothing factor (0.1=max smooth, 1.0=no smooth).

# Queue settings
FRAME_BUFFER_SIZE = 1
DETECTION_BUFFER_SIZE = 1

DETECTION_SKIP_FRAMES = 1  # Sá»‘ frame bá» qua giá»¯a cÃ¡c láº§n detection (0 = detect má»i frame)

# 2. MediaPipe Hand Landmarker
script_dir = os.path.dirname(os.path.abspath(__file__))

# Gá»‘c project: .../Nhom17_DoAnXuLyAnhSo_HCMUTE
project_root = os.path.dirname(os.path.dirname(script_dir))

# Model MediaPipe (.task) dÃ¹ng chung cho TOÃ€N project, Ä‘áº·t táº¡i: Nhom17_DoAnXuLyAnhSo_HCMUTE/models/hand_landmarker.task
HAND_LANDMARKER_MODEL_PATH = os.path.join(project_root, "models", "hand_landmarker.task")

if not os.path.exists(HAND_LANDMARKER_MODEL_PATH):
    raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y model MediaPipe: {HAND_LANDMARKER_MODEL_PATH}")

BaseOptions = mp.tasks.BaseOptions
HandLandmarker = vision.HandLandmarker
HandLandmarkerOptions = vision.HandLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode
base_options = BaseOptions(model_asset_path=HAND_LANDMARKER_MODEL_PATH)

# MediaPipe sá»­ dá»¥ng 2-stage pipeline: BlazePalm (palm detector) + Hand landmark model
# Palm detector chá»‰ cháº¡y khi cáº§n (khi hand presence confidence tháº¥p), khÃ´ng pháº£i má»—i frame
# â†’ GiÃºp tá»‘i Æ°u performance (theo Google Research blog)
options = HandLandmarkerOptions(
    base_options=base_options,
    running_mode=VisionRunningMode.VIDEO,  # dÃ¹ng VIDEO mode cho webcam
    num_hands=NUM_HANDS,
    min_hand_detection_confidence=MIN_DETECTION_CONFIDENCE,
    min_hand_presence_confidence=MIN_PRESENCE_CONFIDENCE,
    min_tracking_confidence=MIN_TRACKING_CONFIDENCE,
)
landmarker = HandLandmarker.create_from_options(options)

# Warm-up: cháº¡y inference Ä‘áº§u tiÃªn Ä‘á»ƒ khá»Ÿi táº¡o model (giáº£m latency spike khi báº¯t Ä‘áº§u)
print("  â†’ Warming up MediaPipe model...")
try:
    dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)
    dummy_frame.flags.writeable = False  # MediaPipe khÃ´ng cáº§n modify image
    dummy_mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=dummy_frame)
    landmarker.detect_for_video(dummy_mp_image, 0)
    print("  â†’ Warm-up completed!")
except Exception as e:
    print(f"  â†’ Warm-up failed (non-critical): {e}")

# EMA Smoothing State
# EMA (Exponential Moving Average) state for each hand
# Structure: {hand_idx: {'landmarks': array, 'last_seen': timestamp}}
ema_state = {}

def apply_ema_smoothing(hand_idx, current_landmarks, alpha=EMA_ALPHA):
    if not ENABLE_EMA_SMOOTHING:
        return current_landmarks
    
    current_time = time.time()
    
    if hand_idx not in ema_state:
        ema_state[hand_idx] = {
            'landmarks': current_landmarks.copy(),
            'last_seen': current_time
        }
        return current_landmarks
    
    prev_landmarks = ema_state[hand_idx]['landmarks']
    smoothed = alpha * current_landmarks + (1 - alpha) * prev_landmarks
    
    ema_state[hand_idx] = {
        'landmarks': smoothed,
        'last_seen': current_time
    }
    
    return smoothed

def cleanup_old_ema_state(current_hand_indices, max_age_seconds=5):
    global ema_state
    current_time = time.time()
    
    # Remove hands not in current frame AND not seen for >max_age_seconds
    ema_state = {
        idx: state for idx, state in ema_state.items() 
        if idx in current_hand_indices or (current_time - state['last_seen']) < max_age_seconds
    }

# 3. Queue & threading setup
stream_url = SOURCE
target_fps = 30.0

print("=" * 60)
print("CAMERA MODE - MediaPipe Hand Landmarker (keypoints + bbox)")

# Tá»‘i Æ°u: DÃ¹ng MSMF backend trÃªn Windows
try:
    temp_cap = cv2.VideoCapture(stream_url, cv2.CAP_MSMF)
except Exception:
    temp_cap = cv2.VideoCapture(stream_url)

if temp_cap.isOpened():
    detected_fps = temp_cap.get(cv2.CAP_PROP_FPS)
    temp_cap.release()
    if detected_fps and detected_fps > 1 and detected_fps < 240:
        target_fps = float(detected_fps)
        print(f"Detected camera FPS: {target_fps:.1f}")
    else:
        print("Detected camera FPS invalid (<=1 or >240). Using 30 FPS fallback.")
else:
    print("Warning: Unable to open camera for FPS detection. Using 30 FPS fallback.")

print(f"Source: {stream_url}")
print(f"Target FPS: {target_fps:.1f}")

total_start = time.time()

print("=" * 60)
print("MULTITHREADING MODE - MediaPipe Hand Landmarker")
print("  Thread 1: Frame Grabber (Ä‘á»c frames tá»« camera)")
print("  Thread 2: Hand Landmarker (detect keypoints + bbox)")
print("  Main Thread: Display (hiá»ƒn thá»‹ káº¿t quáº£)")
print(f"  Frame buffer size: {FRAME_BUFFER_SIZE}")
print(f"  Detection buffer size: {DETECTION_BUFFER_SIZE}")
print("=" * 60)

frame_queue = Queue(maxsize=FRAME_BUFFER_SIZE)
display_frame_queue = Queue(maxsize=FRAME_BUFFER_SIZE)
detection_queue = Queue(maxsize=DETECTION_BUFFER_SIZE)

stop_flag = threading.Event()
queue_drop_count = 0
queue_drop_lock = threading.Lock()

def frame_grabber_thread():
    global queue_drop_count
    try:
        cap = cv2.VideoCapture(stream_url, cv2.CAP_MSMF)  # Windows: MSMF backend
    except Exception:
        cap = cv2.VideoCapture(stream_url)  # Fallback
    
    if not cap.isOpened():
        print(" Error: Cannot open video source")
        stop_flag.set()
        return
    
    # Tá»‘i Æ°u OpenCV settings
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Giáº£m buffer Ä‘á»ƒ giáº£m latency
    cap.set(cv2.CAP_PROP_FPS, target_fps)  # Set FPS náº¿u camera support
    
    frame_id = 0
    while not stop_flag.is_set():
        ret, frame = cap.read()
        if not ret:
            print(" End of stream or error reading frame")
            break
        
        frame_id += 1
        frame_time = time.time()
        
        frame_for_display = frame.copy()
        
        try:
            frame_queue.put((frame_id, frame, frame_time), timeout=0.01)
        except Full:
            with queue_drop_lock:
                queue_drop_count += 1
        
        try:
            display_frame_queue.put((frame_id, frame_for_display, frame_time), timeout=0.01)
        except Full:
            pass
    
    try:
        cap.release()
    except Exception:
        pass
    stop_flag.set()
    print("Thread 1 (Frame Grabber) stopped")


def hand_landmarker_thread():
    global queue_drop_count, is_paused
    
    print("  â†’ HandLandmarker thread: MediaPipe Hand Landmarker (VIDEO mode)")
    
    frame_counter = 0
    
    while not stop_flag.is_set():
        # Check pause Ä‘á»ƒ giáº£m CPU khi pause
        if is_paused:
            time.sleep(0.1)
            continue
        
        try:
            frame_id, frame, frame_time = frame_queue.get(timeout=0.1)
            
            frame_counter += 1
            should_skip = DETECTION_SKIP_FRAMES > 0 and frame_counter % (DETECTION_SKIP_FRAMES + 1) != 0
            
            try:
                if should_skip:
                    # Skip frame nhÆ°ng váº«n cáº§n task_done() á»Ÿ finally
                    continue
                # Convert BGR (OpenCV) sang RGB (MediaPipe yÃªu cáº§u)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                rgb_frame.flags.writeable = False  # MediaPipe khÃ´ng cáº§n modify image
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)

                ts_ms = int(frame_time * 1000)
                t0 = time.time()
                result = landmarker.detect_for_video(mp_image, ts_ms)
                t1 = time.time()
                
                inference_time = t1 - t0
                payload = (frame_id, result, inference_time, t1)

                try:
                    detection_queue.put(payload, timeout=0.01)
                except Full:
                    with queue_drop_lock:
                        queue_drop_count += 1
            except Exception as e:
                print(f"Error in HandLandmarker thread processing: {e}")
            finally:
                # Äáº£m báº£o task_done() chá»‰ Ä‘Æ°á»£c gá»i 1 láº§n cho má»—i frame
                frame_queue.task_done()
            
        except Empty:
            if stop_flag.is_set():
                break
            continue
        except Exception as e:
            print(f"Error in HandLandmarker thread (queue get): {e}")
            continue
    
    print("Thread 2 (HandLandmarker) stopped")


stream_url_str = str(stream_url)
print(f"Starting MediaPipe Hand Landmarker with source: {stream_url_str[:80]}{'...' if len(stream_url_str) > 80 else ''}")

thread1 = threading.Thread(target=frame_grabber_thread, daemon=True)
thread2 = threading.Thread(target=hand_landmarker_thread, daemon=True)

thread1.start()
time.sleep(0.5)
thread2.start()

pred_start = time.time()

# 4. Hiá»ƒn thá»‹ real-time
total_objects = 0
frame_count = 0
MAX_FPS_HISTORY = 300
fps_list = []
frame_intervals = []
display_latencies = []
inference_fps_list = []
inference_times = []
input_fps_list = []

prev_display_time = time.time()
prev_capture_time = None

# Thread-safe shared state: latest_detection Ä‘Æ°á»£c khá»Ÿi táº¡o None á»Ÿ global scope
# Táº¥t cáº£ truy cáº­p Ä‘á»u Ä‘Æ°á»£c báº£o vá»‡ báº±ng latest_detection_lock Ä‘á»ƒ trÃ¡nh race condition
latest_detection = None
latest_detection_lock = threading.Lock()

# Thread-safe shared state: current_frame Ä‘á»ƒ chá»¥p áº£nh ngáº«u nhiÃªn
current_frame = None
current_frame_lock = threading.Lock()

# Cache container size Ä‘á»ƒ trÃ¡nh gá»i winfo_width/height má»—i frame (performance)
cached_container_size = {'w': WINDOW_WIDTH, 'h': WINDOW_HEIGHT, 'last_scale': 1.0, 'last_w': 0, 'last_h': 0}
cached_metrics_values = {}  # Cache metrics values Ä‘á»ƒ chá»‰ update khi thay Ä‘á»•i

# UI State
is_paused = False

# Auto-save hand images settings
SAVE_HAND_IMAGES = False  # Báº­t/táº¯t tá»± Ä‘á»™ng lÆ°u áº£nh
SAVE_DIR = os.path.join(script_dir, "dataset", "S_Test")  # ThÆ° má»¥c lÆ°u áº£nh
save_image_counter = 0  # Äáº¿m sá»‘ áº£nh Ä‘Ã£ lÆ°u
last_save_time = 0  # Thá»i gian lÆ°u áº£nh cuá»‘i cÃ¹ng (Ä‘á»ƒ trÃ¡nh lÆ°u quÃ¡ nhiá»u)
SAVE_INTERVAL = 0.5  # Khoáº£ng thá»i gian tá»‘i thiá»ƒu giá»¯a cÃ¡c láº§n lÆ°u (giÃ¢y)
notification_timer = None  # Timer Ä‘á»ƒ áº©n thÃ´ng bÃ¡o
notification_label = None  # Label hiá»ƒn thá»‹ thÃ´ng bÃ¡o (sáº½ Ä‘Æ°á»£c khá»Ÿi táº¡o trong UI)
root = None  # Tkinter root window (sáº½ Ä‘Æ°á»£c khá»Ÿi táº¡o trong UI)

# Continuous capture state
auto_capture_enabled = False
auto_capture_job = None

def scan_missing_image_numbers(save_dir):
    if not os.path.exists(save_dir):
        return [], 0
    
    try:
        # Láº¥y danh sÃ¡ch táº¥t cáº£ cÃ¡c file trong thÆ° má»¥c
        files = os.listdir(save_dir)
        
        # TÃ¬m táº¥t cáº£ cÃ¡c sá»‘ counter tá»« cÃ¡c file cÃ³ format: NUMBER.jpg
        pattern = re.compile(r"^(\d+)\.jpg$", re.IGNORECASE)
        existing_numbers = set()
        max_counter = -1
        
        for filename in files:
            match = pattern.match(filename)
            if match:
                counter = int(match.group(1))
                existing_numbers.add(counter)
                if counter > max_counter:
                    max_counter = counter
        
        # Náº¿u khÃ´ng cÃ³ file nÃ o, tráº£ vá» list rá»—ng vÃ  báº¯t Ä‘áº§u tá»« 0
        if max_counter < 0:
            return [], 0
        
        # TÃ¬m cÃ¡c sá»‘ cÃ²n thiáº¿u trong khoáº£ng tá»« 0 Ä‘áº¿n max_counter
        missing_numbers = []
        for i in range(max_counter + 1):
            if i not in existing_numbers:
                missing_numbers.append(i)
        
        # Sáº¯p xáº¿p cÃ¡c sá»‘ cÃ²n thiáº¿u Ä‘á»ƒ dÃ¹ng theo thá»© tá»±
        missing_numbers.sort()
        
        # Sá»‘ tiáº¿p theo Ä‘á»ƒ lÆ°u lÃ  max_counter + 1
        next_counter = max_counter + 1
        
        return missing_numbers, next_counter
    except Exception as e:
        print(f" Lá»—i khi quÃ©t thÆ° má»¥c lÆ°u áº£nh: {e}")
        return [], 0

# Khá»Ÿi táº¡o: quÃ©t thÆ° má»¥c vÃ  lÆ°u cÃ¡c sá»‘ cÃ²n thiáº¿u
missing_image_numbers = []  # Queue cÃ¡c sá»‘ cÃ²n thiáº¿u cáº§n láº¥p vÃ o
save_image_counter = 0  # Sá»‘ tiáº¿p theo Ä‘á»ƒ lÆ°u (sau khi Ä‘Ã£ láº¥p háº¿t sá»‘ cÃ²n thiáº¿u)

# QuÃ©t thÆ° má»¥c khi khá»Ÿi Ä‘á»™ng
missing_image_numbers, save_image_counter = scan_missing_image_numbers(SAVE_DIR)
if missing_image_numbers:
    print(f"ÄÃ£ tÃ¬m tháº¥y {len(missing_image_numbers)} sá»‘ cÃ²n thiáº¿u: {missing_image_numbers}")
    print(f"Sáº½ Æ°u tiÃªn láº¥p vÃ o cÃ¡c sá»‘ nÃ y trÆ°á»›c khi tiáº¿p tá»¥c tá»« sá»‘ {save_image_counter}")
elif save_image_counter > 0:
    print(f"ÄÃ£ tÃ¬m tháº¥y {save_image_counter} áº£nh trong thÆ° má»¥c. Báº¯t Ä‘áº§u tá»« sá»‘ {save_image_counter}")

def capture_random_image(silent=False):
    global save_image_counter, last_save_time, notification_label, notification_timer, root
    global missing_image_numbers, current_frame, current_frame_lock, SAVE_HAND_IMAGES
    
    if not silent:
        print("Báº¯t Ä‘áº§u chá»¥p áº£nh ngáº«u nhiÃªn...")
    
    # Cáº£nh bÃ¡o náº¿u auto-save chÆ°a báº­t nhÆ°ng váº«n cho phÃ©p chá»¥p
    if not SAVE_HAND_IMAGES and not silent:
        print("Auto-save chÆ°a báº­t, nhÆ°ng váº«n cho phÃ©p chá»¥p áº£nh ngáº«u nhiÃªn")
    
    # Kiá»ƒm tra khoáº£ng thá»i gian giá»¯a cÃ¡c láº§n lÆ°u
    current_time = time.time()
    if current_time - last_save_time < SAVE_INTERVAL:
        print(f"Vui lÃ²ng Ä‘á»£i {SAVE_INTERVAL:.1f}s giá»¯a cÃ¡c láº§n chá»¥p")
        return
    
    # Láº¥y frame hiá»‡n táº¡i (thread-safe)
    frame = None
    with current_frame_lock:
        if current_frame is not None:
            try:
                frame = current_frame.copy()
                print(f"ÄÃ£ láº¥y frame: {frame.shape if frame is not None else 'None'}")
            except Exception as e:
                print(f"Lá»—i khi copy frame: {e}")
        else:
            print("current_frame lÃ  None - chÆ°a cÃ³ frame nÃ o Ä‘Æ°á»£c lÆ°u")
    
    if frame is None:
        print("ChÆ°a cÃ³ frame Ä‘á»ƒ chá»¥p - vui lÃ²ng Ä‘á»£i camera khá»Ÿi Ä‘á»™ng")
        if notification_label:
            notification_label.config(text=" ChÆ°a cÃ³ frame!", fg='#ffa500')
            if notification_timer:
                root.after_cancel(notification_timer)
            def restore_status():
                if notification_label:
                    if SAVE_HAND_IMAGES:
                        notification_label.config(text=" Auto-save: ON", fg='#00ff00')
                    else:
                        notification_label.config(text=" Auto-save: OFF", fg='#ff6b6b')
            notification_timer = root.after(2000, restore_status)
        return
    
    try:
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
        os.makedirs(SAVE_DIR, exist_ok=True)
        
        frame_h, frame_w = frame.shape[:2]
        target_size = 640
        is_resized = False  # Flag Ä‘á»ƒ theo dÃµi xem cÃ³ resize khÃ´ng
        
        # Xá»­ lÃ½ frame: resize hoáº·c cáº¯t ngáº«u nhiÃªn tÃ¹y kÃ­ch thÆ°á»›c
        if frame_w < target_size or frame_h < target_size:
            # Frame nhá» hÆ¡n 640x640: resize toÃ n bá»™ frame lÃªn 640x640 (giá»¯ tá»· lá»‡ vÃ  pad vá»›i mÃ u Ä‘en)
            print(f"Frame nhá» ({frame_w}x{frame_h}), tá»± Ä‘á»™ng resize lÃªn {target_size}x{target_size}")
            is_resized = True
            
            # TÃ­nh scale Ä‘á»ƒ fit vÃ o 640x640 (giá»¯ tá»· lá»‡)
            scale = min(target_size / frame_w, target_size / frame_h)
            new_w = int(frame_w * scale)
            new_h = int(frame_h * scale)
            
            # Resize frame
            frame_resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
            
            # Táº¡o áº£nh 640x640 vá»›i background Ä‘en
            random_crop = np.zeros((target_size, target_size, 3), dtype=np.uint8)
            
            # Äáº·t áº£nh Ä‘Ã£ resize vÃ o giá»¯a
            y_offset = (target_size - new_h) // 2
            x_offset = (target_size - new_w) // 2
            random_crop[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = frame_resized
            
            random_x = x_offset
            random_y = y_offset
        else:
            # Frame Ä‘á»§ lá»›n: cáº¯t ngáº«u nhiÃªn má»™t vÃ¹ng 640x640
            # Chá»n vá»‹ trÃ­ ngáº«u nhiÃªn Ä‘á»ƒ cáº¯t áº£nh 640x640
            max_x = frame_w - target_size
            max_y = frame_h - target_size
            
            # Äáº£m báº£o max_x vÃ  max_y >= 0
            if max_x < 0:
                max_x = 0
            if max_y < 0:
                max_y = 0
            
            # Random vá»‹ trÃ­ cáº¯t
            random_x = np.random.randint(0, max_x + 1) if max_x > 0 else 0
            random_y = np.random.randint(0, max_y + 1) if max_y > 0 else 0
            
            # Cáº¯t áº£nh 640x640
            random_crop = frame[random_y:random_y+target_size, random_x:random_x+target_size]
        
        if random_crop.size == 0:
            print("KhÃ´ng thá»ƒ xá»­ lÃ½ áº£nh")
            return
        
        # TÃ¬m sá»‘ counter Ä‘á»ƒ lÆ°u: Æ°u tiÃªn dÃ¹ng sá»‘ cÃ²n thiáº¿u trÆ°á»›c
        counter_to_use = None
        
        # Æ¯u tiÃªn 1: DÃ¹ng sá»‘ tá»« danh sÃ¡ch cÃ¡c sá»‘ cÃ²n thiáº¿u
        if missing_image_numbers:
            counter_to_use = missing_image_numbers.pop(0)
        else:
            # Æ¯u tiÃªn 2: DÃ¹ng sá»‘ tiáº¿p theo tá»« counter
            temp_counter = save_image_counter
            max_attempts = 1000
            attempts = 0
            
            while attempts < max_attempts:
                filename_check = f"{temp_counter}.jpg"
                filepath_check = os.path.join(SAVE_DIR, filename_check)
                
                if not os.path.exists(filepath_check):
                    counter_to_use = temp_counter
                    save_image_counter = temp_counter + 1
                    break
                
                temp_counter += 1
                attempts += 1
            
            if attempts >= max_attempts:
                print(f" KhÃ´ng thá»ƒ tÃ¬m Ä‘Æ°á»£c tÃªn file trá»‘ng sau {max_attempts} láº§n thá»­")
                return
        
        # Táº¡o tÃªn file vÃ  Ä‘Æ°á»ng dáº«n
        filename = f"{counter_to_use}.jpg"
        filepath = os.path.join(SAVE_DIR, filename)
        
        # Kiá»ƒm tra láº¡i má»™t láº§n ná»¯a Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n
        if os.path.exists(filepath):
            print(f"File {filename} Ä‘Ã£ tá»“n táº¡i, bá» qua láº§n lÆ°u nÃ y")
            return
        
        # LÆ°u áº£nh
        cv2.imwrite(filepath, random_crop)
        
        # Cáº­p nháº­t thá»i gian
        last_save_time = current_time
        
        # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o
        if notification_label:
            notification_label.config(text=f" ÄÃ£ chá»¥p: {filename}", fg='#00ff00')
        
        # Há»§y timer cÅ© náº¿u cÃ³
        if notification_timer:
            root.after_cancel(notification_timer)
        
        # Tá»± Ä‘á»™ng áº©n thÃ´ng bÃ¡o sau 2 giÃ¢y
        def restore_auto_save_status():
            if notification_label:
                if SAVE_HAND_IMAGES:
                    notification_label.config(text=" Auto-save: ON", fg='#00ff00')
                else:
                    notification_label.config(text=" Auto-save: OFF", fg='#ff6b6b')
        notification_timer = root.after(2000, restore_auto_save_status)
        
        if is_resized:
            print(f"ÄÃ£ chá»¥p vÃ  resize áº£nh: {filepath} (tá»« {frame_w}x{frame_h} lÃªn {target_size}x{target_size})")
        else:
            print(f"ÄÃ£ chá»¥p áº£nh ngáº«u nhiÃªn: {filepath} (vá»‹ trÃ­: x={random_x}, y={random_y})")
        
    except Exception as e:
        print(f"Lá»—i khi chá»¥p áº£nh ngáº«u nhiÃªn: {e}")

# Continuous Random Capture
def start_continuous_capture():
    global auto_capture_enabled, auto_capture_job, notification_label, notification_timer, root
    if auto_capture_enabled:
        print("ÄÃ£ báº­t chá»¥p liÃªn tá»¥c rá»“i")
        return
    auto_capture_enabled = True
    print(f"Báº­t chá»¥p ngáº«u nhiÃªn liÃªn tá»¥c (má»—i {SAVE_INTERVAL}s)")
    
    # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o trong UI
    if notification_label:
        notification_label.config(text=f"Chá»¥p liÃªn tá»¥c: ON ({SAVE_INTERVAL}s)", fg='#00ff00')
        if notification_timer:
            root.after_cancel(notification_timer)
        def restore_status():
            if notification_label:
                if SAVE_HAND_IMAGES:
                    notification_label.config(text="Auto-save: ON", fg='#00ff00')
                else:
                    notification_label.config(text="Auto-save: OFF", fg='#ff6b6b')
        notification_timer = root.after(3000, restore_status)
    
    _schedule_next_capture()


def stop_continuous_capture():
    global auto_capture_enabled, auto_capture_job, notification_label, notification_timer, root
    auto_capture_enabled = False
    if auto_capture_job and root:
        try:
            root.after_cancel(auto_capture_job)
        except Exception:
            pass
    auto_capture_job = None
    print("Táº¯t chá»¥p ngáº«u nhiÃªn liÃªn tá»¥c")
    
    # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o trong UI
    if notification_label:
        notification_label.config(text="Chá»¥p liÃªn tá»¥c: OFF", fg='#ff6b6b')
        if notification_timer:
            root.after_cancel(notification_timer)
        def restore_status():
            if notification_label:
                if SAVE_HAND_IMAGES:
                    notification_label.config(text="Auto-save: ON", fg='#00ff00')
                else:
                    notification_label.config(text=" Auto-save: OFF", fg='#ff6b6b')
        notification_timer = root.after(2000, restore_status)


def _schedule_next_capture():
    global auto_capture_job
    if not auto_capture_enabled or stop_flag.is_set() or root is None:
        return
    try:
        # Chá»¥p áº£nh vá»›i silent=True Ä‘á»ƒ trÃ¡nh spam console
        capture_random_image(silent=True)
    except Exception as e:
        print(f"Lá»—i khi chá»¥p liÃªn tá»¥c: {e}")
    # Láº·p láº¡i sau SAVE_INTERVAL (ms)
    delay_ms = max(int(SAVE_INTERVAL * 1000), 10)
    auto_capture_job = root.after(delay_ms, _schedule_next_capture)


def toggle_continuous_capture():
    if auto_capture_enabled:
        stop_continuous_capture()
    else:
        start_continuous_capture()

# Tkinter UI Setup
try:
    root = tk.Tk()
    root.title("MediaPipe Hand Landmarker - Real-time Detection")
    
    # TÃ­nh toÃ¡n kÃ­ch thÆ°á»›c window
    INFO_PANEL_WIDTH = 350
    total_width = WINDOW_WIDTH + INFO_PANEL_WIDTH + 40
    total_height = WINDOW_HEIGHT + 100
    root.geometry(f"{total_width}x{total_height}")
    root.configure(bg='#1e1e1e')  # Dark background
    root.minsize(800, 500)  # KÃ­ch thÆ°á»›c tá»‘i thiá»ƒu
    
    # CÄƒn giá»¯a window trÃªn mÃ n hÃ¬nh khi khá»Ÿi Ä‘á»™ng
    root.update_idletasks()
    screen_width = root.winfo_screenwidth()
    screen_height = root.winfo_screenheight()
    x = (screen_width - root.winfo_width()) // 2
    y = (screen_height - root.winfo_height()) // 2 - 35
    root.geometry(f"+{x}+{y}")
    
    #  HEADER 
    header_frame = tk.Frame(root, bg='#2d2d2d', height=50)
    header_frame.pack(fill=tk.X, padx=0, pady=0)
    header_frame.pack_propagate(False)
    
    title_label = tk.Label(
        header_frame,
        text="MediaPipe Hand Landmarker",
        font=('Segoe UI', 16, 'bold'),
        bg='#2d2d2d',
        fg='#ffffff'
    )
    title_label.pack(side=tk.LEFT, padx=15, pady=10)
    
    status_label = tk.Label(
        header_frame,
        text="â— Ready",
        font=('Segoe UI', 10),
        bg='#2d2d2d',
        fg='#00ff00'
    )
    status_label.pack(side=tk.RIGHT, padx=15, pady=10)
    
    # Notification label Ä‘á»ƒ hiá»ƒn thá»‹ thÃ´ng bÃ¡o lÆ°u áº£nh
    notification_label = tk.Label(
        header_frame,
        text="",
        font=('Segoe UI', 11, 'bold'),
        bg='#2d2d2d',
        fg='#00ff00'
    )
    notification_label.pack(side=tk.RIGHT, padx=10, pady=10)
    
    # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i auto-save ban Ä‘áº§u khi khá»Ÿi Ä‘á»™ng
    if SAVE_HAND_IMAGES:
        notification_label.config(text=" Auto-save: ON", fg='#00ff00')
    else:
        notification_label.config(text=" Auto-save: OFF", fg='#ff6b6b')
    
    #  MAIN CONTENT AREA 
    main_frame = tk.Frame(root, bg='#1e1e1e')
    main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
    
    #  LEFT SIDE: INFO PANEL 
    info_panel = tk.Frame(main_frame, bg='#252525', width=INFO_PANEL_WIDTH)
    info_panel.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))
    info_panel.pack_propagate(False)
    
    #  GROUP INFO SECTION 
    group_info_frame = tk.Frame(info_panel, bg='#252525')
    group_info_frame.pack(fill=tk.X, padx=15, pady=(15, 10))
    
    group_title = tk.Label(
        group_info_frame,
        text="NhÃ³m 17:",
        font=('Segoe UI', 14, 'bold'),
        bg='#252525',
        fg='#ffffff',
        anchor='w'
    )
    group_title.pack(anchor='w', pady=(0, 8))
    
    # Danh sÃ¡ch thÃ nh viÃªn
    members = [
        "23110203 Pháº¡m Tráº§n ThiÃªn ÄÄƒng",
        "23110235 Pháº¡m VÃµ Nháº¥t Kha",
        "23110280 Huá»³nh Thanh NhÃ¢n",
        "23110327 Huá»³nh Ngá»c Tháº¯ng"
    ]
    
    for member in members:
        member_label = tk.Label(
            group_info_frame,
            text=member,
            font=('Segoe UI', 10, 'bold'),
            bg='#252525',
            fg='#ffffff',
            anchor='w'
        )
        member_label.pack(anchor='w', pady=2)
    
    # Separator line
    separator = tk.Frame(info_panel, bg='#3d3d3d', height=1)
    separator.pack(fill=tk.X, padx=15, pady=10)
    
    # Title cho info panel
    info_title = tk.Label(
        info_panel,
        text="Performance Metrics",
        font=('Segoe UI', 11, 'bold'),
        bg='#252525',
        fg='#ffffff',
        anchor='w'
    )
    info_title.pack(fill=tk.X, padx=15, pady=(0, 8))
    
    # Metrics container vá»›i vertical layout
    metrics_container = tk.Frame(info_panel, bg='#252525')
    metrics_container.pack(fill=tk.X, padx=15, pady=(0, 10))
    
    # Metrics labels (sáº½ Ä‘Æ°á»£c update trong update_frame)
    metrics_labels = {}
    metric_configs = [
        ('target_fps', 'Target FPS', '#00a8ff'),
        ('latency', 'Latency', '#00ff00'),
        ('inference_time', 'Inference Time', '#ffff00'),
        ('objects', 'Objects Detected', '#ff6b6b'),
        ('input_fps', 'Input FPS', '#ffa500'),
        ('inference_fps', 'MediaPipe FPS', '#00a8ff'),
        ('display_fps', 'Display FPS', '#00ff00'),
    ]
    
    # Táº¡o vertical layout cho metrics (gá»n hÆ¡n)
    for key, label, color in metric_configs:
        # Metric container
        metric_frame = tk.Frame(metrics_container, bg='#252525')
        metric_frame.pack(fill=tk.X, pady=3)
        
        # Label name
        name_label = tk.Label(
            metric_frame,
            text=f"{label}:",
            font=('Segoe UI', 8),
            bg='#252525',
            fg='#aaaaaa',
            anchor='w'
        )
        name_label.pack(side=tk.LEFT, padx=(0, 5))
        
        # Value label
        value_label = tk.Label(
            metric_frame,
            text="--",
            font=('Consolas', 9, 'bold'),
            bg='#252525',
            fg=color,
            anchor='w'
        )
        value_label.pack(side=tk.LEFT)
        
        metrics_labels[key] = value_label
    
    # Separator line trÆ°á»›c console
    separator2 = tk.Frame(info_panel, bg='#3d3d3d', height=1)
    separator2.pack(fill=tk.X, padx=15, pady=(10, 8))
    
    #  CONSOLE LOG SECTION 
    console_title = tk.Label(
        info_panel,
        text="Console Log",
        font=('Segoe UI', 11, 'bold'),
        bg='#252525',
        fg='#ffffff',
        anchor='w'
    )
    console_title.pack(fill=tk.X, padx=15, pady=(0, 5))
    
    # Console text widget vá»›i scrollbar
    console_frame = tk.Frame(info_panel, bg='#252525')
    console_frame.pack(fill=tk.BOTH, expand=True, padx=15, pady=(0, 15))
    
    console_text = scrolledtext.ScrolledText(
        console_frame,
        height=8,
        font=('Consolas', 9),
        bg='#1e1e1e',
        fg='#00ff00',
        insertbackground='#00ff00',
        wrap=tk.WORD,
        relief=tk.FLAT,
        borderwidth=0,
        padx=5,
        pady=5
    )
    console_text.pack(fill=tk.BOTH, expand=True)
    console_text.config(state=tk.DISABLED)  # Chá»‰ cho phÃ©p append, khÃ´ng cho edit
    
    # Queue Ä‘á»ƒ buffer messages tá»« cÃ¡c threads (thread-safe)
    console_queue = Queue()
    
    # Class Ä‘á»ƒ redirect stdout vÃ o console widget (thread-safe)
    class ConsoleRedirect:
        def __init__(self, message_queue):
            self.message_queue = message_queue
            self.stdout = sys.stdout
            self.buffer = ""  # Buffer Ä‘á»ƒ tÃ­ch lÅ©y message tá»« nhiá»u láº§n write()
        
        def write(self, message):
            if not message:
                return
            
            # TÃ­ch lÅ©y message vÃ o buffer
            self.buffer += message
            
            # Náº¿u cÃ³ newline trong buffer, tÃ¡ch ra vÃ  Ä‘Æ°a vÃ o queue
            while '\n' in self.buffer:
                line, self.buffer = self.buffer.split('\n', 1)
                # ÄÆ°a tá»«ng dÃ²ng vÃ o queue (má»—i dÃ²ng lÃ  má»™t entry riÃªng)
                self.message_queue.put(line)
        
        def flush(self):
            # Khi flush (print() tá»± Ä‘á»™ng gá»i sau má»—i print()), Ä‘Æ°a pháº§n cÃ²n láº¡i vÃ o queue
            if self.buffer:
                cleaned = self.buffer.rstrip('\r\n')
                if cleaned:  # Chá»‰ Ä‘Æ°a náº¿u cÃ²n ná»™i dung sau khi strip
                    self.message_queue.put(cleaned)
                self.buffer = ""
    
    # Redirect stdout vÃ o console queue
    console_redirect = ConsoleRedirect(console_queue)
    sys.stdout = console_redirect
    
    # Function Ä‘á»ƒ process console queue tá»« main thread
    def process_console_queue():
        try:
            # Kiá»ƒm tra widget váº«n tá»“n táº¡i vÃ  root váº«n alive
            if stop_flag.is_set() or not root.winfo_exists():
                return
            
            while True:
                try:
                    message = console_queue.get_nowait()
                    try:
                        console_text.config(state=tk.NORMAL)
                        # Insert message (Ä‘Ã£ Ä‘Æ°á»£c strip newline rá»“i)
                        console_text.insert(tk.END, message)
                        # LUÃ”N LUÃ”N thÃªm 2 dÃ²ng trá»‘ng Ä‘á»ƒ táº¡o khoáº£ng cÃ¡ch
                        console_text.insert(tk.END, '\n\n')
                        console_text.see(tk.END)  # Auto scroll xuá»‘ng cuá»‘i
                        # Giá»›i háº¡n sá»‘ dÃ²ng (giá»¯ 500 dÃ²ng gáº§n nháº¥t)
                        lines = int(console_text.index('end-1c').split('.')[0])
                        if lines > 500:
                            console_text.delete('1.0', f'{lines-500}.0')
                        console_text.config(state=tk.DISABLED)
                    except (tk.TclError, RuntimeError):
                        # Widget Ä‘Ã£ bá»‹ destroy, restore stdout vÃ  dá»«ng
                        try:
                            sys.stdout = sys.__stdout__
                        except:
                            pass
                        return
                except Empty:
                    break
        except Exception as e:
            # Fallback: print ra stdout gá»‘c náº¿u cÃ³ lá»—i
            try:
                sys.__stdout__.write(f"Console error: {e}\n")
            except:
                pass
        
        # Schedule láº¡i Ä‘á»ƒ check queue tiáº¿p
        if not stop_flag.is_set() and root.winfo_exists():
            root.after(50, process_console_queue)  # Check má»—i 50ms
    
    # Báº¯t Ä‘áº§u process console queue
    root.after(100, process_console_queue)
    
    #  RIGHT SIDE: VIDEO DISPLAY 
    video_panel = tk.Frame(main_frame, bg='#1e1e1e')
    video_panel.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)
    
    # Video container vá»›i border
    video_container = tk.Frame(video_panel, bg='#000000', relief=tk.RAISED, bd=2)
    video_container.pack(fill=tk.BOTH, expand=True)
    
    # Video label (sáº½ fill toÃ n bá»™ container)
    video_label = tk.Label(
        video_container,
        bg='#000000',
        text="Initializing camera...",
        fg='#888888',
        font=('Segoe UI', 12),
        anchor=tk.CENTER,
        justify=tk.CENTER
    )
    video_label.pack(fill=tk.BOTH, expand=True)
    
    # Callback Ä‘á»ƒ update cached container size khi window resize
    def update_container_cache(event=None):
        global cached_container_size
        try:
            w = video_container.winfo_width()
            h = video_container.winfo_height()
            if w > 1 and h > 1:
                cached_container_size['w'] = w
                cached_container_size['h'] = h
        except Exception:
            pass
    
    # Bind resize event Ä‘á»ƒ update cache
    video_container.bind('<Configure>', update_container_cache)
    root.bind('<Configure>', update_container_cache)
    
    #  KEYBOARD SHORTCUTS 
    def toggle_pause():
        global is_paused
        is_paused = not is_paused
        if status_label:
            if is_paused:
                status_label.config(text="â— Paused", fg='#ffa500')
            else:
                status_label.config(text="â— Running", fg='#00ff00')
    
    def toggle_save_images():
        global SAVE_HAND_IMAGES, notification_label, notification_timer
        global missing_image_numbers, save_image_counter
        
        SAVE_HAND_IMAGES = not SAVE_HAND_IMAGES
        
        # Khi báº­t auto-save, quÃ©t láº¡i thÆ° má»¥c Ä‘á»ƒ tÃ¬m cÃ¡c sá»‘ cÃ²n thiáº¿u
        if SAVE_HAND_IMAGES:
            missing_image_numbers, save_image_counter = scan_missing_image_numbers(SAVE_DIR)
            if missing_image_numbers:
                print(f"ÄÃ£ tÃ¬m tháº¥y {len(missing_image_numbers)} sá»‘ cÃ²n thiáº¿u: {missing_image_numbers}")
                print(f"  Sáº½ Æ°u tiÃªn láº¥p vÃ o cÃ¡c sá»‘ nÃ y trÆ°á»›c khi tiáº¿p tá»¥c tá»« sá»‘ {save_image_counter}")
            elif save_image_counter > 0:
                print(f"ÄÃ£ tÃ¬m tháº¥y {save_image_counter} áº£nh trong thÆ° má»¥c. Báº¯t Ä‘áº§u tá»« sá»‘ {save_image_counter}")
            else:
                print(f"ThÆ° má»¥c trá»‘ng. Báº¯t Ä‘áº§u tá»« sá»‘ 0")
        
        if notification_label:
            if SAVE_HAND_IMAGES:
                notification_label.config(text=" Auto-save: ON", fg='#00ff00')
            else:
                notification_label.config(text=" Auto-save: OFF", fg='#ff6b6b')
        
        # Há»§y timer cÅ© náº¿u cÃ³
        if notification_timer:
            root.after_cancel(notification_timer)
        
        # KhÃ´ng tá»± Ä‘á»™ng áº©n tráº¡ng thÃ¡i auto-save (luÃ´n hiá»ƒn thá»‹ Ä‘á»ƒ ngÆ°á»i dÃ¹ng biáº¿t tráº¡ng thÃ¡i)
        # Tráº¡ng thÃ¡i sáº½ chá»‰ bá»‹ thay tháº¿ táº¡m thá»i khi cÃ³ thÃ´ng bÃ¡o lÆ°u áº£nh
        
        print(f" Auto-save images: {'ON' if SAVE_HAND_IMAGES else 'OFF'}")
    
    # Bind keyboard shortcuts
    root.bind('<space>', lambda e: toggle_pause())
    root.bind('<KeyPress-x>', lambda e: toggle_save_images())
    root.bind('<KeyPress-X>', lambda e: toggle_save_images())
    
    # Bind phÃ­m C Ä‘á»ƒ báº­t/táº¯t chá»¥p áº£nh ngáº«u nhiÃªn liÃªn tá»¥c
    def handle_capture(e=None):
        print(" PhÃ­m C Ä‘Æ°á»£c nháº¥n - Báº­t/táº¯t chá»¥p liÃªn tá»¥c")
        try:
            toggle_continuous_capture()
        except NameError:
            print(" Lá»—i: HÃ m toggle_continuous_capture() chÆ°a Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a")
        except Exception as ex:
            print(f" Lá»—i khi toggle chá»¥p liÃªn tá»¥c: {ex}")
    
    # Bind nhiá»u cÃ¡ch Ä‘á»ƒ Ä‘áº£m báº£o hoáº¡t Ä‘á»™ng trÃªn má»i há»‡ thá»‘ng
    root.bind('<Key-c>', handle_capture)
    root.bind('<Key-C>', handle_capture)
    root.bind('<c>', handle_capture)
    root.bind('<C>', handle_capture)
    root.bind_all('<Key-c>', handle_capture)  # Bind toÃ n cá»¥c
    root.bind_all('<Key-C>', handle_capture)   # Bind toÃ n cá»¥c
    
    # Äáº£m báº£o root luÃ´n nháº­n focus Ä‘á»ƒ nháº­n keyboard events
    root.focus_set()
    root.focus_force()  # Force focus
    
    # Bind event Ä‘á»ƒ Ä‘áº£m báº£o focus khi click vÃ o window
    def on_focus_in(e):
        root.focus_set()
    root.bind('<FocusIn>', on_focus_in)
    root.bind('<Button-1>', lambda e: root.focus_set())
    
    # Handle window close
    def on_closing():
        # Restore stdout trÆ°á»›c khi print (trÃ¡nh lá»—i khi widget Ä‘Ã£ bá»‹ destroy)
        try:
            sys.stdout = sys.__stdout__
        except:
            pass
        print("\nStopped by user (closed window)")
        stop_flag.set()
        root.quit()
        root.destroy()
    
    root.protocol("WM_DELETE_WINDOW", on_closing)
    
    #  SETTINGS PANEL 
    settings_window = None
    
    def open_settings():
        """Open settings window"""
        global settings_window
        
        if settings_window is not None:
            try:
                if settings_window.winfo_exists():
                    settings_window.lift()
                    settings_window.focus()
                    return
            except Exception:
                pass
        
        settings_window = tk.Toplevel(root)
        settings_window.title("Settings")
        settings_window.geometry("600x550")
        settings_window.configure(bg='#1e1e1e')
        settings_window.resizable(False, False)
        
        # Center settings window
        settings_window.update_idletasks()
        x = (settings_window.winfo_screenwidth() // 2) - (600 // 2)
        y = (settings_window.winfo_screenheight() // 2) - (550 // 2)
        settings_window.geometry(f"+{x}+{y}")
        
        # Header
        header = tk.Label(
            settings_window,
            text="Settings",
            font=('Segoe UI', 16, 'bold'),
            bg='#2d2d2d',
            fg='#ffffff',
            pady=15
        )
        header.pack(fill=tk.X)
        
        # Content frame
        content_frame = tk.Frame(settings_window, bg='#1e1e1e', padx=20, pady=20)
        content_frame.pack(fill=tk.BOTH, expand=True)
        
        # Container cho 2 cá»™t
        columns_frame = tk.Frame(content_frame, bg='#1e1e1e')
        columns_frame.pack(fill=tk.BOTH, expand=True)
        
        #  COLUMN 1: Performance Settings 
        perf_frame = tk.LabelFrame(
            columns_frame,
            text="Performance Settings",
            font=('Segoe UI', 11, 'bold'),
            bg='#252525',
            fg='#ffffff',
            padx=15,
            pady=15
        )
        perf_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))
        
        # NUM_HANDS
        tk.Label(perf_frame, text="Number of Hands:", bg='#252525', fg='#aaaaaa', anchor='w').pack(fill=tk.X, pady=5)
        num_hands_var = tk.IntVar(value=NUM_HANDS)
        num_hands_scale = tk.Scale(
            perf_frame,
            from_=1,
            to=10,
            orient=tk.HORIZONTAL,
            variable=num_hands_var,
            bg='#252525',
            fg='#ffffff',
            highlightbackground='#252525'
        )
        num_hands_scale.pack(fill=tk.X, pady=5)
        
        # MIN_DETECTION_CONFIDENCE
        tk.Label(perf_frame, text="Min Detection Confidence:", bg='#252525', fg='#aaaaaa', anchor='w').pack(fill=tk.X, pady=5)
        min_det_var = tk.DoubleVar(value=MIN_DETECTION_CONFIDENCE)
        min_det_scale = tk.Scale(
            perf_frame,
            from_=0.1,
            to=1.0,
            resolution=0.1,
            orient=tk.HORIZONTAL,
            variable=min_det_var,
            bg='#252525',
            fg='#ffffff',
            highlightbackground='#252525'
        )
        min_det_scale.pack(fill=tk.X, pady=5)
        
        # MIN_TRACKING_CONFIDENCE
        tk.Label(perf_frame, text="Min Tracking Confidence:", bg='#252525', fg='#aaaaaa', anchor='w').pack(fill=tk.X, pady=5)
        min_track_var = tk.DoubleVar(value=MIN_TRACKING_CONFIDENCE)
        min_track_scale = tk.Scale(
            perf_frame,
            from_=0.1,
            to=1.0,
            resolution=0.1,
            orient=tk.HORIZONTAL,
            variable=min_track_var,
            bg='#252525',
            fg='#ffffff',
            highlightbackground='#252525'
        )
        min_track_scale.pack(fill=tk.X, pady=5)
        
        # MIN_PRESENCE_CONFIDENCE
        tk.Label(perf_frame, text="Min Presence Confidence:", bg='#252525', fg='#aaaaaa', anchor='w').pack(fill=tk.X, pady=5)
        min_presence_var = tk.DoubleVar(value=MIN_PRESENCE_CONFIDENCE)
        min_presence_scale = tk.Scale(
            perf_frame,
            from_=0.1,
            to=1.0,
            resolution=0.1,
            orient=tk.HORIZONTAL,
            variable=min_presence_var,
            bg='#252525',
            fg='#ffffff',
            highlightbackground='#252525'
        )
        min_presence_scale.pack(fill=tk.X, pady=5)
        
        #  COLUMN 2: EMA Settings 
        ema_frame = tk.LabelFrame(
            columns_frame,
            text="EMA Smoothing",
            font=('Segoe UI', 11, 'bold'),
            bg='#252525',
            fg='#ffffff',
            padx=15,
            pady=15
        )
        ema_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=(10, 0))
        
        # ENABLE_EMA_SMOOTHING
        ema_enable_var = tk.BooleanVar(value=ENABLE_EMA_SMOOTHING)
        tk.Checkbutton(
            ema_frame,
            text="Enable EMA Smoothing",
            variable=ema_enable_var,
            bg='#252525',
            fg='#ffffff',
            selectcolor='#1e1e1e',
            activebackground='#252525',
            activeforeground='#ffffff'
        ).pack(anchor='w', pady=5)
        
        # EMA_ALPHA
        tk.Label(ema_frame, text="EMA Alpha:", bg='#252525', fg='#aaaaaa', anchor='w').pack(fill=tk.X, pady=5)
        ema_alpha_var = tk.DoubleVar(value=EMA_ALPHA)
        ema_alpha_scale = tk.Scale(
            ema_frame,
            from_=0.1,
            to=1.0,
            resolution=0.1,
            orient=tk.HORIZONTAL,
            variable=ema_alpha_var,
            bg='#252525',
            fg='#ffffff',
            highlightbackground='#252525'
        )
        ema_alpha_scale.pack(fill=tk.X, pady=5)
        
        # Separator
        separator1 = tk.Frame(ema_frame, bg='#3d3d3d', height=1)
        separator1.pack(fill=tk.X, pady=15)
        
        # Auto-save Settings
        save_title = tk.Label(
            ema_frame,
            text="Auto-save Settings",
            font=('Segoe UI', 10, 'bold'),
            bg='#252525',
            fg='#ffffff',
            anchor='w'
        )
        save_title.pack(anchor='w', pady=(0, 5))
        
        # SAVE_HAND_IMAGES
        save_images_var = tk.BooleanVar(value=SAVE_HAND_IMAGES)
        tk.Checkbutton(
            ema_frame,
            text="Auto-save Hand Images",
            variable=save_images_var,
            bg='#252525',
            fg='#ffffff',
            selectcolor='#1e1e1e',
            activebackground='#252525',
            activeforeground='#ffffff'
        ).pack(anchor='w', pady=5)
        
        # Save Directory Selection
        save_dir_frame = tk.Frame(ema_frame, bg='#252525')
        save_dir_frame.pack(fill=tk.X, pady=(10, 5))
        
        tk.Label(
            save_dir_frame,
            text="ThÆ° má»¥c lÆ°u áº£nh:",
            bg='#252525',
            fg='#aaaaaa',
            anchor='w',
            font=('Segoe UI', 9)
        ).pack(anchor='w', pady=(0, 5))
        
        # Frame chá»©a Ä‘Æ°á»ng dáº«n vÃ  nÃºt
        save_dir_path_frame = tk.Frame(save_dir_frame, bg='#252525')
        save_dir_path_frame.pack(fill=tk.X)
        
        # Label hiá»ƒn thá»‹ Ä‘Æ°á»ng dáº«n (cÃ³ thá»ƒ cuá»™n náº¿u dÃ i)
        save_dir_label = tk.Label(
            save_dir_path_frame,
            text=SAVE_DIR,
            bg='#1e1e1e',
            fg='#ffffff',
            anchor='w',
            font=('Consolas', 8),
            relief=tk.SUNKEN,
            bd=1,
            padx=5,
            pady=3,
            wraplength=250
        )
        save_dir_label.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        
        # NÃºt chá»n thÆ° má»¥c
        def browse_save_dir():
            global SAVE_DIR, missing_image_numbers, save_image_counter, SAVE_HAND_IMAGES
            selected_dir = filedialog.askdirectory(
                title="Chá»n thÆ° má»¥c lÆ°u áº£nh",
                initialdir=SAVE_DIR if os.path.exists(SAVE_DIR) else script_dir
            )
            if selected_dir:  # Náº¿u ngÆ°á»i dÃ¹ng chá»n thÆ° má»¥c (khÃ´ng cancel)
                SAVE_DIR = selected_dir
                # Cáº­p nháº­t label hiá»ƒn thá»‹
                save_dir_label.config(text=SAVE_DIR)
                print(f" ÄÃ£ chá»n thÆ° má»¥c lÆ°u áº£nh: {SAVE_DIR}")
                
                # Náº¿u auto-save Ä‘ang báº­t, quÃ©t láº¡i thÆ° má»¥c má»›i Ä‘á»ƒ tÃ¬m cÃ¡c sá»‘ cÃ²n thiáº¿u
                if SAVE_HAND_IMAGES:
                    missing_image_numbers, save_image_counter = scan_missing_image_numbers(SAVE_DIR)
                    if missing_image_numbers:
                        print(f" ÄÃ£ tÃ¬m tháº¥y {len(missing_image_numbers)} sá»‘ cÃ²n thiáº¿u: {missing_image_numbers}")
                        print(f"  Sáº½ Æ°u tiÃªn láº¥p vÃ o cÃ¡c sá»‘ nÃ y trÆ°á»›c khi tiáº¿p tá»¥c tá»« sá»‘ {save_image_counter}")
                    elif save_image_counter > 0:
                        print(f" ÄÃ£ tÃ¬m tháº¥y {save_image_counter} áº£nh trong thÆ° má»¥c. Báº¯t Ä‘áº§u tá»« sá»‘ {save_image_counter}")
                    else:
                        print(f" ThÆ° má»¥c trá»‘ng. Báº¯t Ä‘áº§u tá»« sá»‘ 0")
        
        browse_btn = tk.Button(
            save_dir_path_frame,
            text="ğŸ“ Chá»n",
            command=browse_save_dir,
            bg='#00a8ff',
            fg='#ffffff',
            font=('Segoe UI', 9),
            padx=10,
            pady=3,
            cursor='hand2',
            relief=tk.RAISED,
            bd=1
        )
        browse_btn.pack(side=tk.RIGHT)
        
        # Buttons (luÃ´n á»Ÿ bottom, khÃ´ng bá»‹ che)
        button_frame = tk.Frame(settings_window, bg='#1e1e1e', pady=15, padx=20)
        button_frame.pack(fill=tk.X, side=tk.BOTTOM)
        
        def apply_settings():
            global NUM_HANDS, MIN_DETECTION_CONFIDENCE, MIN_PRESENCE_CONFIDENCE, MIN_TRACKING_CONFIDENCE
            global ENABLE_EMA_SMOOTHING, EMA_ALPHA, landmarker, SAVE_HAND_IMAGES, SAVE_DIR
            global missing_image_numbers, save_image_counter
            
            new_num_hands = num_hands_var.get()
            new_min_det = min_det_var.get()
            new_min_track = min_track_var.get()
            new_min_presence = min_presence_var.get()
            new_ema_enable = ema_enable_var.get()
            new_ema_alpha = ema_alpha_var.get()
            new_save_images = save_images_var.get()
            
            # Ãp dá»¥ng EMA settings ngay
            ENABLE_EMA_SMOOTHING = new_ema_enable
            EMA_ALPHA = new_ema_alpha
            
            # Ãp dá»¥ng Auto-save settings ngay
            old_save_state = SAVE_HAND_IMAGES
            old_save_dir = SAVE_DIR
            SAVE_HAND_IMAGES = new_save_images
            
            # Náº¿u thÆ° má»¥c lÆ°u áº£nh thay Ä‘á»•i hoáº·c báº­t auto-save (tá»« OFF sang ON), quÃ©t láº¡i thÆ° má»¥c
            if (SAVE_HAND_IMAGES and not old_save_state) or (SAVE_HAND_IMAGES and SAVE_DIR != old_save_dir):
                missing_image_numbers, save_image_counter = scan_missing_image_numbers(SAVE_DIR)
                if missing_image_numbers:
                    print(f" ÄÃ£ tÃ¬m tháº¥y {len(missing_image_numbers)} sá»‘ cÃ²n thiáº¿u: {missing_image_numbers}")
                    print(f"  Sáº½ Æ°u tiÃªn láº¥p vÃ o cÃ¡c sá»‘ nÃ y trÆ°á»›c khi tiáº¿p tá»¥c tá»« sá»‘ {save_image_counter}")
                elif save_image_counter > 0:
                    print(f" ÄÃ£ tÃ¬m tháº¥y {save_image_counter} áº£nh trong thÆ° má»¥c. Báº¯t Ä‘áº§u tá»« sá»‘ {save_image_counter}")
                else:
                    print(f" ThÆ° má»¥c trá»‘ng. Báº¯t Ä‘áº§u tá»« sá»‘ 0")
            
            # Kiá»ƒm tra xem cÃ³ cáº§n recreate landmarker khÃ´ng
            need_recreate = (
                NUM_HANDS != new_num_hands or
                MIN_DETECTION_CONFIDENCE != new_min_det or
                MIN_PRESENCE_CONFIDENCE != new_min_presence or
                MIN_TRACKING_CONFIDENCE != new_min_track
            )
            
            if need_recreate:
                # Update global variables
                NUM_HANDS = new_num_hands
                MIN_DETECTION_CONFIDENCE = new_min_det
                MIN_PRESENCE_CONFIDENCE = new_min_presence
                MIN_TRACKING_CONFIDENCE = new_min_track
                
                # Recreate landmarker vá»›i options má»›i
                try:
                    # ÄÃ³ng landmarker cÅ©
                    if landmarker:
                        landmarker.close()
                    
                    # Táº¡o options má»›i
                    new_options = HandLandmarkerOptions(
                        base_options=base_options,
                        running_mode=VisionRunningMode.VIDEO,
                        num_hands=NUM_HANDS,
                        min_hand_detection_confidence=MIN_DETECTION_CONFIDENCE,
                        min_hand_presence_confidence=MIN_PRESENCE_CONFIDENCE,
                        min_tracking_confidence=MIN_TRACKING_CONFIDENCE,
                    )
                    
                    # Táº¡o landmarker má»›i
                    landmarker = HandLandmarker.create_from_options(new_options)
                    
                    # Warm-up landmarker má»›i
                    dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                    dummy_frame.flags.writeable = False
                    dummy_mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=dummy_frame)
                    landmarker.detect_for_video(dummy_mp_image, 0)
                    
                    print(f" Landmarker recreated with new settings:")
                    print(f"  NUM_HANDS={NUM_HANDS}, MIN_DET={MIN_DETECTION_CONFIDENCE:.2f}, "
                          f"MIN_PRESENCE={MIN_PRESENCE_CONFIDENCE:.2f}, MIN_TRACK={MIN_TRACKING_CONFIDENCE:.2f}")
                except Exception as e:
                    print(f" Error recreating landmarker: {e}")
                    return
            
            print(f" Settings applied:")
            print(f"  NUM_HANDS={NUM_HANDS}, MIN_DET={MIN_DETECTION_CONFIDENCE:.2f}, "
                  f"MIN_PRESENCE={MIN_PRESENCE_CONFIDENCE:.2f}, MIN_TRACK={MIN_TRACKING_CONFIDENCE:.2f}")
            print(f"  EMA={ENABLE_EMA_SMOOTHING}, ALPHA={EMA_ALPHA:.2f}")
            print(f"  Auto-save Images={SAVE_HAND_IMAGES}")
            print(f"  Save Directory={SAVE_DIR}")
        
        def close_settings():
            global settings_window
            if settings_window:
                settings_window.destroy()
            settings_window = None
        
        tk.Button(
            button_frame,
            text="Apply",
            command=apply_settings,
            bg='#00a8ff',
            fg='#ffffff',
            font=('Segoe UI', 10, 'bold'),
            padx=20,
            pady=5,
            cursor='hand2'
        ).pack(side=tk.LEFT, padx=5)
        
        tk.Button(
            button_frame,
            text="Close",
            command=close_settings,
            bg='#666666',
            fg='#ffffff',
            font=('Segoe UI', 10),
            padx=20,
            pady=5,
            cursor='hand2'
        ).pack(side=tk.LEFT, padx=5)
        
        # Handle close
        settings_window.protocol("WM_DELETE_WINDOW", close_settings)
    
    # Settings button in header
    settings_btn = tk.Button(
        header_frame,
        text="âš™ Settings",
        command=open_settings,
        bg='#2d2d2d',
        fg='#ffffff',
        font=('Segoe UI', 9),
        relief=tk.FLAT,
        padx=10,
        pady=5,
        cursor='hand2',
        activebackground='#3d3d3d',
        activeforeground='#ffffff'
    )
    settings_btn.pack(side=tk.RIGHT, padx=5)
    
    # Capture button in header (Ä‘á»ƒ báº­t/táº¯t chá»¥p liÃªn tá»¥c)
    capture_btn = tk.Button(
        header_frame,
        text="ğŸ“· Chá»¥p liÃªn tá»¥c (C)",
        command=toggle_continuous_capture,
        bg='#2d2d2d',
        fg='#00ff00',
        font=('Segoe UI', 9),
        relief=tk.FLAT,
        padx=10,
        pady=5,
        cursor='hand2',
        activebackground='#3d3d3d',
        activeforeground='#00ff00'
    )
    capture_btn.pack(side=tk.RIGHT, padx=5)
    
    print(" Tkinter UI initialized")
except Exception as e:
    raise RuntimeError(f"KhÃ´ng thá»ƒ khá»Ÿi táº¡o Tkinter UI: {e}") from e

current_photo = None

# Helper Functions
def limit_list_size(data_list, max_size):
    """Giá»›i háº¡n kÃ­ch thÆ°á»›c list, chá»‰ giá»¯ N giÃ¡ trá»‹ gáº§n nháº¥t"""
    if len(data_list) > max_size:
        return data_list[-max_size:]
    return data_list

def fps_text(val, avg=None):
    """Format FPS text vá»›i optional average value"""
    return f"{val:.1f} (avg: {avg:.1f})" if avg is not None else f"{val:.1f}"

def ms_text(val, avg=None):
    """Format milliseconds text vá»›i optional average value"""
    return f"{val:.1f}ms (avg: {avg:.1f}ms)" if avg is not None else f"{val:.1f}ms"

def moving_avg(data_list, window=30):
    """TÃ­nh trung bÃ¬nh trÆ°á»£t (moving average)"""
    if not data_list:
        return None
    return sum(data_list[-window:]) / min(window, len(data_list))

def get_track_color(track_id):
    """Táº¡o mÃ u á»•n Ä‘á»‹nh tá»« track_id"""
    hash_val = hash(str(track_id)) % (256**3)
    r = max(100, (hash_val & 0xFF0000) >> 16)
    g = max(100, (hash_val & 0x00FF00) >> 8)
    b = max(100, hash_val & 0x0000FF)
    return (r, g, b)

def save_hand_image(frame, min_x, min_y, max_x, max_y):
    global save_image_counter, last_save_time, notification_label, notification_timer, root
    global missing_image_numbers
    
    # Kiá»ƒm tra khoáº£ng thá»i gian giá»¯a cÃ¡c láº§n lÆ°u
    current_time = time.time()
    if current_time - last_save_time < SAVE_INTERVAL:
        return
    
    try:
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
        os.makedirs(SAVE_DIR, exist_ok=True)
        
        # Cáº¯t áº£nh tá»« bounding box (thÃªm padding nhá» Ä‘á»ƒ khÃ´ng bá»‹ cáº¯t)
        padding = 20
        frame_h, frame_w = frame.shape[:2]
        
        # TÃ­nh toÃ¡n tá»a Ä‘á»™ vá»›i padding
        crop_x1 = max(0, min_x - padding)
        crop_y1 = max(0, min_y - padding)
        crop_x2 = min(frame_w, max_x + padding)
        crop_y2 = min(frame_h, max_y + padding)
        
        # Cáº¯t áº£nh
        hand_crop = frame[crop_y1:crop_y2, crop_x1:crop_x2]
        
        if hand_crop.size == 0:
            return
        
        # Resize vá» 640x640 (giá»¯ tá»· lá»‡ vÃ  pad vá»›i mÃ u Ä‘en náº¿u cáº§n)
        target_size = 640
        h, w = hand_crop.shape[:2]
        
        # TÃ­nh scale Ä‘á»ƒ fit vÃ o 640x640
        scale = min(target_size / w, target_size / h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        # Resize
        hand_resized = cv2.resize(hand_crop, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        # Táº¡o áº£nh 640x640 vá»›i background Ä‘en
        hand_final = np.zeros((target_size, target_size, 3), dtype=np.uint8)
        
        # Äáº·t áº£nh Ä‘Ã£ resize vÃ o giá»¯a
        y_offset = (target_size - new_h) // 2
        x_offset = (target_size - new_w) // 2
        hand_final[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = hand_resized
        
        # TÃ¬m sá»‘ counter Ä‘á»ƒ lÆ°u: Æ°u tiÃªn dÃ¹ng sá»‘ cÃ²n thiáº¿u trÆ°á»›c
        counter_to_use = None
        
        # Æ¯u tiÃªn 1: DÃ¹ng sá»‘ tá»« danh sÃ¡ch cÃ¡c sá»‘ cÃ²n thiáº¿u
        if missing_image_numbers:
            counter_to_use = missing_image_numbers.pop(0)  # Láº¥y sá»‘ Ä‘áº§u tiÃªn vÃ  xÃ³a khá»i list
        else:
            # Æ¯u tiÃªn 2: DÃ¹ng sá»‘ tiáº¿p theo tá»« counter
            # Kiá»ƒm tra xem sá»‘ nÃ y Ä‘Ã£ tá»“n táº¡i chÆ°a (phÃ²ng trÆ°á»ng há»£p cÃ³ file má»›i Ä‘Æ°á»£c thÃªm vÃ o tá»« bÃªn ngoÃ i)
            temp_counter = save_image_counter
            max_attempts = 1000
            attempts = 0
            
            while attempts < max_attempts:
                filename_check = f"{temp_counter}.jpg"
                filepath_check = os.path.join(SAVE_DIR, filename_check)
                
                # Náº¿u file chÆ°a tá»“n táº¡i, dÃ¹ng sá»‘ nÃ y
                if not os.path.exists(filepath_check):
                    counter_to_use = temp_counter
                    save_image_counter = temp_counter + 1  # Cáº­p nháº­t counter cho láº§n sau
                    break
                
                # Náº¿u file Ä‘Ã£ tá»“n táº¡i, thá»­ sá»‘ tiáº¿p theo
                temp_counter += 1
                attempts += 1
            
            if attempts >= max_attempts:
                print(f" KhÃ´ng thá»ƒ tÃ¬m Ä‘Æ°á»£c tÃªn file trá»‘ng sau {max_attempts} láº§n thá»­")
                return
        
        # Táº¡o tÃªn file vÃ  Ä‘Æ°á»ng dáº«n
        filename = f"{counter_to_use}.jpg"
        filepath = os.path.join(SAVE_DIR, filename)
        
        # Kiá»ƒm tra láº¡i má»™t láº§n ná»¯a Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n (phÃ²ng trÆ°á»ng há»£p cÃ³ race condition)
        if os.path.exists(filepath):
            print(f" File {filename} Ä‘Ã£ tá»“n táº¡i, bá» qua láº§n lÆ°u nÃ y")
            return
        
        # LÆ°u áº£nh
        cv2.imwrite(filepath, hand_final)
        
        # Cáº­p nháº­t thá»i gian
        last_save_time = current_time
        
        # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o
        if notification_label:
            notification_label.config(text=f" ÄÃ£ lÆ°u: {filename}", fg='#00ff00')
        
        # Há»§y timer cÅ© náº¿u cÃ³
        if notification_timer:
            root.after_cancel(notification_timer)
        
        # Tá»± Ä‘á»™ng áº©n thÃ´ng bÃ¡o sau 2 giÃ¢y vÃ  quay láº¡i hiá»ƒn thá»‹ tráº¡ng thÃ¡i auto-save
        def restore_auto_save_status():
            if notification_label:
                if SAVE_HAND_IMAGES:
                    notification_label.config(text=" Auto-save: ON", fg='#00ff00')
                else:
                    notification_label.config(text=" Auto-save: OFF", fg='#ff6b6b')
        notification_timer = root.after(2000, restore_auto_save_status)
        
        print(f" ÄÃ£ lÆ°u áº£nh: {filepath}")
        
    except Exception as e:
        print(f" Lá»—i khi lÆ°u áº£nh: {e}")

def draw_keypoints(frame, keypoints, color=(0, 255, 255), radius=3, conf_threshold=0.3):
    """
    Váº½ keypoints lÃªn frame (tá»‘i Æ°u cho real-time vá»›i OpenCV direct calls)
    
    Performance: Custom OpenCV nhanh hÆ¡n MediaPipe official draw_landmarks vÃ¬:
    - KhÃ´ng cÃ³ protobuf conversion overhead
    - Direct C++ OpenCV backend
    - CÃ³ thá»ƒ tá»‘i Æ°u validation vÃ  bounds checking
    
    Args:
        frame: Frame Ä‘á»ƒ váº½
        keypoints: numpy array shape (num_keypoints, 3) vá»›i (x, y, confidence) hoáº·c (num_keypoints, 2) vá»›i (x, y)
        color: MÃ u keypoints (BGR)
        radius: BÃ¡n kÃ­nh Ä‘iá»ƒm keypoint
        conf_threshold: NgÆ°á»¡ng confidence tá»‘i thiá»ƒu Ä‘á»ƒ váº½ keypoint
    """
    if keypoints is None or len(keypoints) == 0:
        return
    
    frame_h, frame_w = frame.shape[:2]
    
    radius_outer = radius + 1
    white = (255, 255, 255)
    
    # Keypoints shape: (num_keypoints, 3) vá»›i (x, y, confidence) hoáº·c (num_keypoints, 2) vá»›i (x, y)
    for kp in keypoints:
        if len(kp) >= 2:
            x, y = float(kp[0]), float(kp[1])
            conf = float(kp[2]) if len(kp) > 2 else 1.0
            
            # Váº½ keypoint náº¿u confidence Ä‘á»§ vÃ  tá»a Ä‘á»™ há»£p lá»‡ (>= 0 vÃ  < frame size)
            if conf >= conf_threshold and 0 <= x < frame_w and 0 <= y < frame_h:
                x, y = int(x), int(y)
                # Váº½ Ä‘iá»ƒm keypoint vá»›i viá»n tráº¯ng má»ng Ä‘á»ƒ dá»… nhÃ¬n
                cv2.circle(frame, (x, y), radius_outer, white, -1)  # Viá»n tráº¯ng
                cv2.circle(frame, (x, y), radius, color, -1)  # Äiá»ƒm keypoint

def draw_hand_skeleton(frame, keypoints, color=(0, 255, 255), thickness=1, conf_threshold=0.3):
    """
    Váº½ skeleton connections cho hand keypoints (21 keypoints cho hand)
    
    Cáº¥u trÃºc 21 keypoints theo MediaPipe:
    - 0: Wrist (cá»• tay)
    - 1-4: Thumb (ngÃ³n cÃ¡i): 1=CMC, 2=MCP, 3=IP, 4=Tip
    - 5-8: Index (ngÃ³n trá»): 5=MCP, 6=PIP, 7=DIP, 8=Tip
    - 9-12: Middle (ngÃ³n giá»¯a): 9=MCP, 10=PIP, 11=DIP, 12=Tip
    - 13-16: Ring (ngÃ³n Ã¡p Ãºt): 13=MCP, 14=PIP, 15=DIP, 16=Tip
    - 17-20: Pinky (ngÃ³n Ãºt): 17=MCP, 18=PIP, 19=DIP, 20=Tip
    
    Connections nÃ y khá»›p vá»›i MediaPipe solutions.hands.HAND_CONNECTIONS
    
    Args:
        frame: Frame Ä‘á»ƒ váº½
        keypoints: numpy array shape (21, 3) vá»›i (x, y, confidence) hoáº·c (21, 2) vá»›i (x, y)
        color: MÃ u Ä‘Æ°á»ng ná»‘i (BGR)
        thickness: Äá»™ dÃ y Ä‘Æ°á»ng ná»‘i
        conf_threshold: NgÆ°á»¡ng confidence tá»‘i thiá»ƒu Ä‘á»ƒ váº½ connection
    """
    if keypoints is None or len(keypoints) < 21:
        return
    
    frame_h, frame_w = frame.shape[:2]
    
    # Hand keypoint connections theo MediaPipe HAND_CONNECTIONS
    # Wrist to finger bases (CMC cho thumb, MCP cho cÃ¡c ngÃ³n khÃ¡c)
    wrist_to_fingers = [(0, 1), (0, 5), (0, 9), (0, 13), (0, 17)]
    
    # Thumb: CMC -> MCP -> IP -> Tip
    thumb_chain = [(1, 2), (2, 3), (3, 4)]
    
    # Index finger: MCP -> PIP -> DIP -> Tip
    index_chain = [(5, 6), (6, 7), (7, 8)]
    
    # Middle finger: MCP -> PIP -> DIP -> Tip
    middle_chain = [(9, 10), (10, 11), (11, 12)]
    
    # Ring finger: MCP -> PIP -> DIP -> Tip
    ring_chain = [(13, 14), (14, 15), (15, 16)]
    
    # Pinky finger: MCP -> PIP -> DIP -> Tip
    pinky_chain = [(17, 18), (18, 19), (19, 20)]
    
    # Táº¥t cáº£ connections
    all_connections = wrist_to_fingers + thumb_chain + index_chain + middle_chain + ring_chain + pinky_chain
    
    for start_idx, end_idx in all_connections:
        if start_idx < len(keypoints) and end_idx < len(keypoints):
            kp1 = keypoints[start_idx]
            kp2 = keypoints[end_idx]
            
            if len(kp1) >= 2 and len(kp2) >= 2:
                x1, y1 = float(kp1[0]), float(kp1[1])
                x2, y2 = float(kp2[0]), float(kp2[1])
                conf1 = float(kp1[2]) if len(kp1) > 2 else 1.0
                conf2 = float(kp2[2]) if len(kp2) > 2 else 1.0
                
                if (
                    conf1 >= conf_threshold
                    and conf2 >= conf_threshold
                    and 0 <= x1 < frame_w
                    and 0 <= y1 < frame_h
                    and 0 <= x2 < frame_w
                    and 0 <= y2 < frame_h
                ):
                    pt1 = (int(x1), int(y1))
                    pt2 = (int(x2), int(y2))
                    cv2.line(frame, pt1, pt2, color, thickness)

# Main Update Loop
def update_frame():
    global frame_count, total_objects, prev_display_time, prev_capture_time
    global latest_detection, current_photo
    global inference_fps_list, inference_times, input_fps_list, fps_list, frame_intervals, display_latencies
    global cached_container_size, cached_metrics_values, is_paused, notification_timer
    global current_frame, current_frame_lock
    
    if stop_flag.is_set():
        if root:
            root.quit()
        return
    
    # Skip update if paused
    if is_paused:
        if root and not stop_flag.is_set():
            root.after(200, update_frame)  # Check láº¡i sau 200ms
        return
    
    try:
        # Láº¥y frame má»›i nháº¥t tá»« display_frame_queue (skip frames cÅ© Ä‘á»ƒ giáº£m lag)
        frame_id, frame_original, frame_time = None, None, None
        
        try:
            # Láº¥y táº¥t cáº£ frames vÃ  chá»‰ giá»¯ frame má»›i nháº¥t (skip frames cÅ©)
            while True:
                frame_id, frame_original, frame_time = display_frame_queue.get_nowait()
                display_frame_queue.task_done()
        except Empty:
            if frame_original is None:
                try:
                    frame_id, frame_original, frame_time = display_frame_queue.get(timeout=0.01)
                    display_frame_queue.task_done()
                except Empty:
                    # Schedule next update
                    if root and not stop_flag.is_set():
                        root.after(10, update_frame)
                    return
        
        if frame_original is None:
            if root and not stop_flag.is_set():
                root.after(10, update_frame)
            return
        
        # Láº¥y kÃ­ch thÆ°á»›c frame tá»« frame_original (sau khi Ä‘Ã£ check None)
        try:
            frame_w, frame_h = frame_original.shape[1], frame_original.shape[0]
        except (AttributeError, IndexError) as e:
            print(f" Error getting frame dimensions: {e}")
            if root and not stop_flag.is_set():
                root.after(10, update_frame)
            return
        
        # LÆ°u frame hiá»‡n táº¡i Ä‘á»ƒ cÃ³ thá»ƒ chá»¥p áº£nh ngáº«u nhiÃªn (thread-safe)
        with current_frame_lock:
            current_frame = frame_original.copy()
        
        # Check detection_queue non-blocking Ä‘á»ƒ láº¥y hand landmarks má»›i nháº¥t
        result = None
        inference_time = 0
        inference_end_time = None
        
        try:
            detection_data = detection_queue.get_nowait()
            frame_id_det, result, inference_time, inference_end_time = detection_data
            detection_queue.task_done()
            with latest_detection_lock:
                latest_detection = (result, inference_time, inference_end_time)
            # Kiá»ƒm tra inference_time > 0 trÆ°á»›c khi tÃ­nh reciprocal (trÃ¡nh ZeroDivision)
            if inference_time > 0:
                inference_fps_list.append(1.0 / inference_time)
                inference_fps_list = limit_list_size(inference_fps_list, MAX_FPS_HISTORY)
                inference_times.append(inference_time)
                inference_times = limit_list_size(inference_times, MAX_FPS_HISTORY)
        except Empty:
            with latest_detection_lock:
                if latest_detection is not None:
                    result, inference_time, inference_end_time = latest_detection
        
        # Äo Input FPS thá»±c táº¿
        if prev_capture_time is not None:
            capture_interval = frame_time - prev_capture_time
            if capture_interval > 0:
                input_fps_list.append(1.0 / capture_interval)
                input_fps_list = limit_list_size(input_fps_list, MAX_FPS_HISTORY)
        prev_capture_time = frame_time
        
        # TÃ­nh latency (chá»‰ khi cÃ³ inference_end_time há»£p lá»‡)
        current_display_time = time.time()
        if inference_end_time is not None:
            display_latency = current_display_time - inference_end_time
            display_latencies.append(display_latency)
            display_latencies = limit_list_size(display_latencies, MAX_FPS_HISTORY)
        else:
            display_latency = 0  # ChÆ°a cÃ³ detection nÃ o
        
        # TÃ­nh frame interval
        if frame_count == 0:
            frame_interval = 0
            prev_display_time = current_display_time
        else:
            frame_interval = current_display_time - prev_display_time
            prev_display_time = current_display_time
        
        if frame_interval > 0:
            frame_intervals.append(frame_interval)
            frame_intervals = limit_list_size(frame_intervals, MAX_FPS_HISTORY)
        
        frame_count += 1
        
        # Sá»‘ bÃ n tay (dá»±a trÃªn MediaPipe)
        num_objects = 0
        if result and result.hand_landmarks:
            num_objects = len(result.hand_landmarks)
        total_objects += num_objects
        
        # TÃ­nh FPS hiá»ƒn thá»‹
        current_fps = None
        if frame_interval > 0:
            current_fps = 1.0 / frame_interval
            fps_list.append(current_fps)
            fps_list = limit_list_size(fps_list, MAX_FPS_HISTORY)
        
        # TÃ­nh trung bÃ¬nh cÃ¡c FPS metrics
        current_inference_fps = 1.0 / inference_time if inference_time > 0 else None
        avg_fps_display = moving_avg(fps_list)
        avg_inference_fps_display = moving_avg(inference_fps_list)
        avg_input_fps_display = moving_avg(input_fps_list)
        avg_display_latency = moving_avg(display_latencies)
        avg_inference_time = moving_avg(inference_times)
        current_input_fps = input_fps_list[-1] if input_fps_list else None
        
        # Visualization (MediaPipe hand landmarks + bounding box)
        annotated_frame = frame_original.copy()
        
        if result and result.hand_landmarks:
            try:
                # Cleanup old EMA state (prevent memory leak)
                current_hand_indices = set(range(len(result.hand_landmarks)))
                cleanup_old_ema_state(current_hand_indices)
                
                for hand_idx, landmarks in enumerate(result.hand_landmarks):
                    # landmarks: list 21 Ä‘iá»ƒm, má»—i Ä‘iá»ƒm cÃ³ x, y (normalized)
                    # Validate vÃ  clamp x, y trong khoáº£ng [0, 1] Ä‘á»ƒ trÃ¡nh crash náº¿u MediaPipe tráº£ vá» giÃ¡ trá»‹ lá»—i
                    landmarks_array = np.array([
                        [max(0.0, min(1.0, lm.x)) * frame_w, max(0.0, min(1.0, lm.y)) * frame_h, 1.0] 
                        for lm in landmarks
                    ], dtype=np.float32)
                    
                    # Apply EMA smoothing to reduce jitter
                    landmarks_array = apply_ema_smoothing(hand_idx, landmarks_array, alpha=EMA_ALPHA)
                    
                    xs = landmarks_array[:, 0]
                    ys = landmarks_array[:, 1]

                    # Bounding box theo keypoints
                    min_x, max_x = int(xs.min()), int(xs.max())
                    min_y, max_y = int(ys.min()), int(ys.max())
                
                    # Lá»c theo kÃ­ch thÆ°á»›c box
                    box_w = max_x - min_x
                    box_h = max_y - min_y
                    if box_w <= 0 or box_h <= 0:
                        continue
                    box_area = box_w * box_h
                    frame_area = float(frame_w * frame_h)
                    area_ratio = box_area / frame_area if frame_area > 0 else 0.0

                    # Bá» box quÃ¡ nhá» (nhiá»…u) hoáº·c quÃ¡ lá»›n (thÆ°á»ng lÃ  gáº§n camera)
                    if area_ratio < HAND_MIN_AREA_RATIO or area_ratio > HAND_MAX_AREA_RATIO:
                        continue

                    # Lá»c thÃªm theo Ä‘á»™ tin cáº­y handedness Ä‘á»ƒ trÃ¡nh patch má» má» bá»‹ gÃ¡n tay
                    handedness_label = "Hand"
                    handedness_score = 1.0
                    if result.handedness and len(result.handedness) > hand_idx:
                        entry = result.handedness[hand_idx]
                        # Xá»­ lÃ½ an toÃ n: entry cÃ³ thá»ƒ lÃ  list/tuple hoáº·c object trá»±c tiáº¿p
                        if isinstance(entry, (list, tuple)) and len(entry) > 0:
                            cat = entry[0]
                        else:
                            cat = entry
                        
                        # Äá»c category_name vÃ  score (há»— trá»£ nhiá»u version MediaPipe)
                        name = getattr(cat, "category_name", None) or getattr(cat, "label", None) or "Hand"
                        score = getattr(cat, "score", None) or getattr(cat, "confidence", None) or 1.0
                        handedness_label = f"{name}:{float(score):.2f}"
                        handedness_score = float(score)
                    # Náº¿u Ä‘á»™ tin cáº­y handedness quÃ¡ tháº¥p thÃ¬ bá» qua (khÃ´ng váº½ tay)
                    # Loáº¡i bá» cÃ¡c detection khÃ´ng cháº¯c cháº¯n (cÃ³ thá»ƒ lÃ  false positive)
                    if handedness_score < HANDEDNESS_SCORE_THRESHOLD:
                        continue

                    color = get_track_color(hand_idx)  # dÃ¹ng index tay lÃ m ID táº¡m

                    label = f"ID:{hand_idx} {handedness_label}"
                    
                    # Váº½ bounding box
                    cv2.rectangle(annotated_frame, (min_x, min_y), (max_x, max_y), color, 2)
                    (text_width, text_height), baseline = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
                    )
                    # Äáº£m báº£o text box khÃ´ng váº½ ra ngoÃ i frame (y >= 0)
                    text_y_start = max(0, min_y - text_height - baseline - 3)
                    text_y_end = min_y
                    cv2.rectangle(
                        annotated_frame,
                        (min_x, text_y_start),
                        (min_x + text_width, text_y_end),
                        color,
                        -1,
                    )
                    # Äáº£m báº£o text luÃ´n visible (trÃ¡nh edge case khi min_y ráº¥t nhá»)
                    text_y = max(text_height + baseline + 2, min_y - baseline - 1)
                    white = (255, 255, 255)
                    cv2.putText(
                        annotated_frame,
                        label,
                        (min_x, text_y),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        white,
                        1,
                    )
                    
                    # Skeleton + keypoints
                    draw_hand_skeleton(annotated_frame, landmarks_array, color, 1, conf_threshold=0.0)
                    draw_keypoints(annotated_frame, landmarks_array, color, 3, conf_threshold=0.0)
                    
                    # Tá»± Ä‘á»™ng lÆ°u áº£nh bÃ n tay (raw data - khÃ´ng cÃ³ keypoints)
                    if SAVE_HAND_IMAGES:
                        save_hand_image(frame_original, min_x, min_y, max_x, max_y)

            except Exception as e:
                print(f" Error drawing MediaPipe results: {e}")
        
        # Hiá»ƒn thá»‹ vá»›i Tkinter
        try:
            # Convert BGR to RGB for PIL
            rgb_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
            
            # Resize Ä‘á»ƒ fill video container (scale vÃ  crop center Ä‘á»ƒ khÃ´ng cÃ³ mÃ u Ä‘en)
            h, w = rgb_frame.shape[:2]
            try:
                # Láº¥y kÃ­ch thÆ°á»›c video container tá»« cache (trÃ¡nh gá»i winfo má»—i frame)
                container_w = cached_container_size.get('w', WINDOW_WIDTH)
                container_h = cached_container_size.get('h', WINDOW_HEIGHT)
                
                # Náº¿u container chÆ°a Ä‘Æ°á»£c render, dÃ¹ng default size
                if container_w <= 1 or container_h <= 1:
                    container_w = WINDOW_WIDTH
                    container_h = WINDOW_HEIGHT
                
                # Cache resize parameters Ä‘á»ƒ trÃ¡nh tÃ­nh láº¡i má»—i frame
                cache_key = f"{w}_{h}_{container_w}_{container_h}"
                if ('last_resize_key' not in cached_container_size or 
                    cached_container_size['last_resize_key'] != cache_key):
                    # TÃ­nh láº¡i resize parameters khi size thay Ä‘á»•i
                    scale_w = container_w / w
                    scale_h = container_h / h
                    scale = max(scale_w, scale_h)
                    
                    new_w = int(w * scale)
                    new_h = int(h * scale)
                    
                    # Cache láº¡i Ä‘á»ƒ dÃ¹ng cho frame tiáº¿p theo
                    cached_container_size['last_resize_key'] = cache_key
                    cached_container_size['cached_scale'] = scale
                    cached_container_size['cached_new_w'] = new_w
                    cached_container_size['cached_new_h'] = new_h
                else:
                    # DÃ¹ng láº¡i cached values khi size khÃ´ng Ä‘á»•i
                    scale = cached_container_size['cached_scale']
                    new_w = cached_container_size['cached_new_w']
                    new_h = cached_container_size['cached_new_h']
                
                # Resize vá»›i cached parameters
                if abs(scale - 1.0) > 0.01:
                    interpolation = cv2.INTER_AREA if scale < 1.0 else cv2.INTER_LINEAR
                    rgb_frame = cv2.resize(rgb_frame, (new_w, new_h), interpolation=interpolation)
                
                # Crop center Ä‘á»ƒ fit container (vá»›i validation Ä‘á»ƒ trÃ¡nh crash)
                if new_w > container_w or new_h > container_h:
                    start_x = max(0, min((new_w - container_w) // 2, new_w - container_w))
                    start_y = max(0, min((new_h - container_h) // 2, new_h - container_h))
                    end_x = min(new_w, start_x + container_w)
                    end_y = min(new_h, start_y + container_h)
                    rgb_frame = rgb_frame[start_y:end_y, start_x:end_x]
                elif new_w < container_w or new_h < container_h:
                    # Pad vá»›i mÃ u Ä‘en náº¿u nhá» hÆ¡n container (Ã­t khi xáº£y ra)
                    pad_w = (container_w - new_w) // 2
                    pad_h = (container_h - new_h) // 2
                    rgb_frame = cv2.copyMakeBorder(
                        rgb_frame, pad_h, container_h - new_h - pad_h,
                        pad_w, container_w - new_w - pad_w,
                        cv2.BORDER_CONSTANT, value=[0, 0, 0]
                    )
            except Exception:
                # Fallback: giá»¯ nguyÃªn kÃ­ch thÆ°á»›c
                pass
            
            # Reuse PhotoImage object Ä‘á»ƒ tá»‘i Æ°u performance (PIL.ImageTk.PhotoImage cÃ³ paste() method)
            pil_image = Image.fromarray(rgb_frame)
            
            if not hasattr(video_label, 'photo_image') or video_label.photo_image is None:
                # Láº§n Ä‘áº§u: táº¡o má»›i PhotoImage
                video_label.photo_image = ImageTk.PhotoImage(image=pil_image)
                video_label.photo_image_size = pil_image.size
                video_label.config(image=video_label.photo_image, text="")
            else:
                # Update PhotoImage hiá»‡n cÃ³ náº¿u size giá»‘ng nhau (dÃ¹ng paste() - nhanh hÆ¡n)
                try:
                    if hasattr(video_label, 'photo_image_size') and pil_image.size == video_label.photo_image_size:
                        # DÃ¹ng paste() Ä‘á»ƒ update image (tá»± Ä‘á»™ng reflect, khÃ´ng cáº§n recreate)
                        video_label.photo_image.paste(pil_image)
                    else:
                        # Táº¡o má»›i náº¿u size thay Ä‘á»•i
                        video_label.photo_image = ImageTk.PhotoImage(image=pil_image)
                        video_label.photo_image_size = pil_image.size
                        video_label.config(image=video_label.photo_image, text="")
                except Exception:
                    # Fallback: táº¡o má»›i PhotoImage náº¿u cÃ³ lá»—i
                    video_label.photo_image = ImageTk.PhotoImage(image=pil_image)
                    video_label.photo_image_size = pil_image.size
                    video_label.config(image=video_label.photo_image, text="")
            
            # Update status (khÃ´ng override náº¿u Ä‘ang pause)
            if status_label and not is_paused:
                if current_fps is not None and avg_fps_display is not None:
                    status_label.config(text="â— Running", fg='#00ff00')
            
            # Update metrics labels (chá»‰ update khi giÃ¡ trá»‹ thay Ä‘á»•i)
            if metrics_labels:
                if current_fps is not None and avg_fps_display is not None:
                    # TÃ­nh toÃ¡n cÃ¡c giÃ¡ trá»‹ má»›i
                    new_values = {
                        'target_fps': f"{target_fps:.1f}",
                        'display_fps': fps_text(current_fps, avg_fps_display),
                        'inference_fps': fps_text(current_inference_fps, avg_inference_fps_display) if current_inference_fps else '--',
                        'input_fps': fps_text(current_input_fps, avg_input_fps_display) if current_input_fps else '--',
                        'latency': ms_text(display_latency*1000, avg_display_latency*1000 if avg_display_latency else None),
                        'inference_time': ms_text(inference_time*1000, avg_inference_time*1000 if avg_inference_time else None),
                        'objects': f"{num_objects}"
                    }
                    
                    # Chá»‰ update labels khi giÃ¡ trá»‹ thay Ä‘á»•i
                    for key, new_value in new_values.items():
                        if key not in cached_metrics_values or cached_metrics_values[key] != new_value:
                            metrics_labels[key].config(text=new_value)
                            cached_metrics_values[key] = new_value
                else:
                    # ChÆ°a cÃ³ FPS data (chÆ°a khá»Ÿi Ä‘á»™ng xong)
                    init_values = {
                        'target_fps': f"{target_fps:.1f}",
                        'display_fps': '--',
                        'inference_fps': '--',
                        'input_fps': '--',
                        'latency': '--',
                        'inference_time': '--',
                        'objects': f"{num_objects}"
                    }
                    
                    # Chá»‰ update labels khi giÃ¡ trá»‹ thay Ä‘á»•i
                    for key, new_value in init_values.items():
                        if key not in cached_metrics_values or cached_metrics_values[key] != new_value:
                            metrics_labels[key].config(text=new_value)
                            cached_metrics_values[key] = new_value
        except Exception as e:
            print(f" Error updating Tkinter UI: {e}")
        
        # Print info (thá»‘ng kÃª FPS / latency)
        if frame_count % PRINT_EVERY_N_FRAMES == 0 or frame_count <= 5:
            if len(fps_list) > 0:
                avg_frame_interval = (moving_avg(frame_intervals) or 0) * 1000
                avg_display_latency = (moving_avg(display_latencies) or 0) * 1000
                avg_fps_print = avg_fps_display or moving_avg(fps_list) or 0
                avg_inference_fps_print = moving_avg(inference_fps_list) or 0
                avg_input_fps_print = moving_avg(input_fps_list) or 0
                print(
                    f"  â†’ Average Display FPS: {avg_fps_print:.1f} | "
                    f"Average MediaPipe FPS: {avg_inference_fps_print:.1f} | "
                    f"Average Input FPS: {avg_input_fps_print:.1f} | "
                    f"Target FPS: {target_fps:.1f} | "
                    f"Frame interval: {avg_frame_interval:.1f}ms | "
                    f"Display latency: {avg_display_latency:.1f}ms | "
                    f"Inference: {inference_time*1000:.1f}ms"
                )
        
        # Schedule next update
        if not stop_flag.is_set():
            delay = 10  # 10ms delay
            root.after(delay, update_frame)
        
    except Exception as e:
        print(f" Error in update_frame: {e}")
        if not stop_flag.is_set():
            root.after(10, update_frame)

# Cháº¡y Tkinter main loop
root.after(10, update_frame)
root.mainloop()

# 5. Cleanup & Summary
# Dá»«ng táº¥t cáº£ threads
stop_flag.set()

# Queue cleanup: dÃ¹ng get_nowait() vá»›i Empty exception
try:
    while True:
        try:
            frame_queue.get_nowait()
            frame_queue.task_done()
        except Empty:
            break
    while True:
        try:
            display_frame_queue.get_nowait()
            display_frame_queue.task_done()
        except Empty:
            break
    while True:
        try:
            detection_queue.get_nowait()
            detection_queue.task_done()
        except Empty:
            break
except Exception:
    pass

# Äá»£i threads káº¿t thÃºc hoÃ n toÃ n
if thread1.is_alive():
    thread1.join(timeout=3)
if thread2.is_alive():
    thread2.join(timeout=3)

# ÄÃ³ng landmarker Ä‘á»ƒ giáº£i phÃ³ng tÃ i nguyÃªn
try:
    landmarker.close()
except Exception:
    pass

# Cleanup Tkinter (náº¿u chÆ°a Ä‘Æ°á»£c destroy)
try:
    if root.winfo_exists():
        root.quit()
        root.destroy()
except Exception:
    pass

pred_end = time.time()
pred_time = pred_end - pred_start

# TÃ­nh toÃ¡n thá»‘ng kÃª cuá»‘i cÃ¹ng
avg_fps = sum(fps_list) / len(fps_list) if fps_list else 0
avg_frame_interval = sum(frame_intervals) / len(frame_intervals) * 1000 if frame_intervals else 0
avg_display_latency = sum(display_latencies) / len(display_latencies) * 1000 if display_latencies else 0
min_display_latency = min(display_latencies) * 1000 if display_latencies else 0
max_display_latency = max(display_latencies) * 1000 if display_latencies else 0
avg_inference_fps = sum(inference_fps_list) / len(inference_fps_list) if inference_fps_list else 0
avg_input_fps = sum(input_fps_list) / len(input_fps_list) if input_fps_list else 0

total_end = time.time()

# Restore stdout vá» gá»‘c Ä‘á»ƒ print summary ra terminal (trÃ¡nh lá»—i khi widget Ä‘Ã£ bá»‹ destroy)
try:
    sys.stdout = sys.__stdout__
except:
    pass

print(f"\n{'='*60}")
print(f"REALTIME SUMMARY - MEDIAPIPE HAND LANDMARKER:")
print(f"  Backend: MediaPipe (hand_landmarker.task)")
print(f"  Total frames processed: {frame_count}")
print(f"  Total objects detected: {total_objects}")
print(f"  Target FPS: {target_fps:.1f}")
print(f"  Average Display FPS: {avg_fps:.2f}")
print(f"  Average MediaPipe FPS: {avg_inference_fps:.2f}")
print(f"  Average Input FPS: {avg_input_fps:.2f}")
print(f"  Average frame interval: {avg_frame_interval:.2f}ms")
print(f"  Average display latency: {avg_display_latency:.2f}ms")
print(f"  Min display latency: {min_display_latency:.2f}ms | Max display latency: {max_display_latency:.2f}ms")
print(f"  Total inference time: {pred_time:.2f}s")
print(f"  Total script time: {total_end - total_start:.2f} seconds")
with queue_drop_lock:
    print(f"  Queue drops (frames): {queue_drop_count}")
if avg_fps > 0:
    efficiency = (avg_fps / target_fps) * 100
    print(f"  Efficiency: {efficiency:.1f}% (vs target FPS)")